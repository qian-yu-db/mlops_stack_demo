name: Feature and Training Unit and Integration Tests for mlops_stack_demo
on:
  workflow_dispatch:
  pull_request:
    paths:
      - 'mlops_stack_demo/**'
      - '.github/workflows/mlops_stack_demo-run-tests.yml'

defaults:
  run:
    working-directory: ./mlops_stack_demo/

env:
  DATABRICKS_HOST: https://e2-demo-field-eng.cloud.databricks.com
  DATABRICKS_TOKEN: ${{ secrets.DEV_WORKSPACE_TOKEN }}

concurrency: mlops_stack_demo-feature-training-integration-test-dev

jobs:
  unit_tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      # Feature store tests bring up a local Spark session, so Java is required.
      - uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'
      - name: Install dependencies
        run: |
            python -m pip install --upgrade pip
            pip install -r requirements.txt
            pip install -r ../test-requirements.txt
      - name: Run tests with pytest
        run: |
            pytest

  integration_test:
    needs: unit_tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - uses: databricks/setup-cli@v0.236.0
      - name: Validate Bundle For Dev Deployment Target
        id: validate
        run: |
          databricks bundle validate -t dev
      - name: Deploy Bundle to Dev Deployment Target
        id: deploy
        run: |
          databricks bundle deploy -t dev
      - name: Run Feature Engineering Workflow for Dev Deployment Target
        id: feature_engineering
        run: |
          databricks bundle run write_feature_table_job -t dev
      - name: Run Training Workflow for Dev Deployment Target
        id: training
        run: |
          databricks bundle run model_training_job -t dev
